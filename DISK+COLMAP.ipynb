{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mediapy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-25T09:06:27.237065Z","iopub.execute_input":"2023-09-25T09:06:27.238167Z","iopub.status.idle":"2023-09-25T09:06:39.128823Z","shell.execute_reply.started":"2023-09-25T09:06:27.238128Z","shell.execute_reply":"2023-09-25T09:06:39.127449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get some utility functions from https://github.com/cvg/Hierarchical-Localization/\n\n%cd /kaggle/working/\n!rm -rf /kaggle/working/Hierarchical-Localization\n!git clone --quiet --recursive https://github.com/cvg/Hierarchical-Localization/\n%cd /kaggle/working/Hierarchical-Localization\n!pip install -e .\n\nfrom hloc import extract_features, match_features, reconstruction, visualization, pairs_from_exhaustive\nfrom hloc.visualization import plot_images, read_image\nfrom hloc.utils import viz_3d\n\n%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:44:47.232184Z","iopub.execute_input":"2023-09-25T09:44:47.232571Z","iopub.status.idle":"2023-09-25T09:45:24.917906Z","shell.execute_reply.started":"2023-09-25T09:44:47.232541Z","shell.execute_reply":"2023-09-25T09:45:24.916679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pycolmap\nimport numpy as np\nimport mediapy as media\nimport cv2\nfrom glob import glob\nfrom pathlib import Path\nfrom time import time","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:07:01.781960Z","iopub.execute_input":"2023-09-25T09:07:01.782358Z","iopub.status.idle":"2023-09-25T09:07:01.975317Z","shell.execute_reply.started":"2023-09-25T09:07:01.782327Z","shell.execute_reply":"2023-09-25T09:07:01.973858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = 'urban'\nscene = 'kyiv-puppet-theater'\n#src = f'/kaggle/input/image-matching-challenge-2023/train/{dataset}/{scene}'\n#src = f'/kaggle/input/minitape3d'\n#src=f'/kaggle/input/tape-3d'\nsrc=f'/kaggle/input/shoe-half-size'\n#images = [cv2.cvtColor(cv2.imread(im), cv2.COLOR_BGR2RGB) for im in glob(f'/kaggle/input/tape-3d/*')]\nimages = [cv2.cvtColor(cv2.imread(im), cv2.COLOR_BGR2RGB) for im in glob(f'/kaggle/input/shoe-half-size/*')]","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:07:04.164699Z","iopub.execute_input":"2023-09-25T09:07:04.165623Z","iopub.status.idle":"2023-09-25T09:07:08.352548Z","shell.execute_reply.started":"2023-09-25T09:07:04.165588Z","shell.execute_reply":"2023-09-25T09:07:08.351367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"media.show_images(images, height=300, columns=4)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:07:09.796733Z","iopub.execute_input":"2023-09-25T09:07:09.798073Z","iopub.status.idle":"2023-09-25T09:07:20.416952Z","shell.execute_reply.started":"2023-09-25T09:07:09.798030Z","shell.execute_reply":"2023-09-25T09:07:20.415522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DISK\n\nthe DISK local feature extractor.\n\nWe will have to write code to extract features, and then import them into the colmap database. \n\nYou can find examples here: [imc2023-kornia-starter-pack](https://github.com/ducha-aiki/imc2023-kornia-starter-pack.git).","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/\n!rm -rf /kaggle/working/imc2023-kornia-starter-pack\n!git clone --quiet --recursive https://github.com/ducha-aiki/imc2023-kornia-starter-pack.git\n\nimport sys\nsys.path.append('/kaggle/working/imc2023-kornia-starter-pack')\n\nimport kornia as K\nimport kornia.feature as KF\nimport torch\nimport h5py\nfrom fastprogress import progress_bar\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:08:47.785683Z","iopub.execute_input":"2023-09-25T09:08:47.787009Z","iopub.status.idle":"2023-09-25T09:08:57.650626Z","shell.execute_reply.started":"2023-09-25T09:08:47.786969Z","shell.execute_reply":"2023-09-25T09:08:57.649625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will need images in pytorch format\ndef load_torch_image(fname, device=torch.device('cpu')):\n    img = K.image_to_tensor(cv2.imread(fname), False).float() / 255.\n    img = K.color.bgr_to_rgb(img.to(device))\n    return img\n\n# Load DISK w/o internet connection through Kaggle Models voodoo: while not necessary yet, it will be helpful for offline submissions, which require turning off internet access.\ndef load_DISK(device=torch.device('cpu')):\n    disk = KF.DISK().to(device)\n    pretrained_dict = torch.load('/kaggle/input/disk/pytorch/depth-supervision/1/loftr_outdoor.ckpt', map_location=device)\n    disk.load_state_dict(pretrained_dict['extractor'])\n    disk.eval()\n    return disk","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:09:04.527614Z","iopub.execute_input":"2023-09-25T09:09:04.528038Z","iopub.status.idle":"2023-09-25T09:09:04.535998Z","shell.execute_reply.started":"2023-09-25T09:09:04.528006Z","shell.execute_reply":"2023-09-25T09:09:04.534910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_features(img_fnames,\n                    num_feats = 2048,\n                    device=torch.device('cpu'),\n                    feature_dir = '.featureout'):\n    disk = load_DISK(device)\n    if not os.path.isdir(feature_dir):\n        os.makedirs(feature_dir)\n    \n    # We will save features to h5 files, and then will import them into colmap\n    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n        for img_path in progress_bar(img_fnames):\n            img_fname = img_path.split('/')[-1]\n            key = img_fname\n            with torch.inference_mode():\n                timg = load_torch_image(img_path, device=device)\n                features = disk(timg, num_feats, pad_if_not_divisible=True)[0]\n                kpts, descs = features.keypoints, features.descriptors\n            \n            # Convert to numpy to store in h5py\n            kpts = kpts.reshape(-1, 2).detach().cpu().numpy()\n            descs = descs.reshape(-1, 128).detach().cpu().numpy()\n            f_kp[key] = kpts\n            f_desc[key] = descs\n    return\n\nimg_fnames =  [fname for fname in glob(f'/kaggle/input/shoe-half-size/*')]\nfeature_dir = 'disk_features'\ndevice=torch.device('cuda')\ndetect_features(img_fnames, 5000, device=device, feature_dir=feature_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:09:07.426762Z","iopub.execute_input":"2023-09-25T09:09:07.427739Z","iopub.status.idle":"2023-09-25T09:10:02.526062Z","shell.execute_reply.started":"2023-09-25T09:09:07.427701Z","shell.execute_reply":"2023-09-25T09:10:02.524951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n# kornia_moons for feature visualization\n!pip install kornia_moons","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:10:11.303512Z","iopub.execute_input":"2023-09-25T09:10:11.303993Z","iopub.status.idle":"2023-09-25T09:10:23.398621Z","shell.execute_reply.started":"2023-09-25T09:10:11.303955Z","shell.execute_reply":"2023-09-25T09:10:23.397271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's visualize our detections\nfrom kornia_moons.feature import visualize_LAF\n\nimage_index = 10\nwith h5py.File(f'{feature_dir}/keypoints.h5', mode='r') as f_kp:\n    img1 = load_torch_image(img_fnames[image_index])\n    key = img_fnames[image_index].split('/')[-1]\n    lafs = KF.laf_from_center_scale_ori(torch.from_numpy(f_kp[key][...]).reshape(1,-1, 2))\n    visualize_LAF(img1, lafs)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:10:29.390483Z","iopub.execute_input":"2023-09-25T09:10:29.390916Z","iopub.status.idle":"2023-09-25T09:10:34.996452Z","shell.execute_reply.started":"2023-09-25T09:10:29.390882Z","shell.execute_reply":"2023-09-25T09:10:34.995371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will match our features on GPU with kornia\n\ndef match_features(img_fnames,\n                   index_pairs,\n                   feature_dir = '.featureout',\n                   device=torch.device('cpu'),\n                   min_matches=15, verbose = True):\n    with h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n         h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n        for pair_idx in progress_bar(index_pairs):\n                    idx1, idx2 = pair_idx\n                    fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n                    key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n                    desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n                    desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n                    # Matching with mutual nearest neighbor check and Lowe's threshold\n                    dists, idxs = KF.match_smnn(desc1, desc2, 0.98)\n                    if len(idxs)  == 0:\n                        continue\n                    n_matches = len(idxs)\n                    if verbose:\n                        print (f'{key1}-{key2}: {n_matches} matches')\n                    group  = f_match.require_group(key1)\n                    if n_matches >= min_matches:\n                         group.create_dataset(key2, data=idxs.detach().cpu().numpy().reshape(-1, 2))\n    return\n\n# matching all to all\nindex_pairs = []\nfor i in range(len(img_fnames)):\n    for j in range(i+1, len(img_fnames)):\n        index_pairs.append((i,j))\n\nmatch_features(img_fnames, index_pairs, device=torch.device('cuda'), feature_dir=feature_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:10:59.984296Z","iopub.execute_input":"2023-09-25T09:10:59.985264Z","iopub.status.idle":"2023-09-25T09:14:16.813513Z","shell.execute_reply.started":"2023-09-25T09:10:59.985217Z","shell.execute_reply":"2023-09-25T09:14:16.812528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import into colmap\n\nfrom h5_to_db import import_into_colmap\ntgt=f'/kaggle/working/'\ndatabase_path = f'{tgt}/database_disk.db'\n!rm -rf {database_path}\nimg_dir = src\n\nimport_into_colmap(img_dir, database_path=database_path, feature_dir=feature_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:17:45.387624Z","iopub.execute_input":"2023-09-25T09:17:45.388383Z","iopub.status.idle":"2023-09-25T09:17:48.032080Z","shell.execute_reply.started":"2023-09-25T09:17:45.388337Z","shell.execute_reply":"2023-09-25T09:17:48.030876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we run colmap. First matching - because it is bundled with RANSAC.\n# Don't worry, colmap would not match our features again, it will just estimate geometry.\noutput_path =  f'{tgt}/disk_reconstruction'\nos.makedirs(output_path, exist_ok=True)\npycolmap.match_exhaustive(database_path)\n\n# Then we run reconstruction, as before\nmaps = pycolmap.incremental_mapping(database_path, img_dir, output_path)","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:18:00.842911Z","iopub.execute_input":"2023-09-25T09:18:00.843320Z","iopub.status.idle":"2023-09-25T09:43:19.427492Z","shell.execute_reply.started":"2023-09-25T09:18:00.843288Z","shell.execute_reply":"2023-09-25T09:43:19.426241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maps","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:44:09.277917Z","iopub.execute_input":"2023-09-25T09:44:09.278622Z","iopub.status.idle":"2023-09-25T09:44:09.285863Z","shell.execute_reply.started":"2023-09-25T09:44:09.278585Z","shell.execute_reply":"2023-09-25T09:44:09.284836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect the largest map generated by DISK + colmap. \n# Note that it might produce more than one reconstruction.\n\nbest_index = None\nbest_num_reg_images = 0\nfor idx in maps:\n    if maps[idx].num_reg_images() > best_num_reg_images:\n        best_index = idx\n        best_num_reg_images = maps[idx].num_reg_images()\n\nif best_num_reg_images > 0:\n    print(f'Looking at reconstruction #{best_index} with {best_num_reg_images} registered images')\n    fig = viz_3d.init_figure()\n    viz_3d.plot_reconstruction(fig, maps[best_index], color='rgba(0,0,255,0.5)', name=\"Reconstruction\", cs=3, cameras=False)\n    viz_3d.plot_reconstruction(fig, maps[best_index], color='rgba(255,0,0,0.5)', name=\"Reconstruction\", cs=3, points=False)\n    fig.show()\nelse:\n    print('No reconstruction. :(')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T09:45:38.701155Z","iopub.execute_input":"2023-09-25T09:45:38.702194Z","iopub.status.idle":"2023-09-25T09:45:43.829555Z","shell.execute_reply.started":"2023-09-25T09:45:38.702136Z","shell.execute_reply":"2023-09-25T09:45:43.828430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}